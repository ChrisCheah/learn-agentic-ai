{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7ad23195",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain in c:\\users\\cheahchr\\git\\learn-agentic-ai\\.venv\\lib\\site-packages (1.0.8)\n",
      "Requirement already satisfied: langchain-openai in c:\\users\\cheahchr\\git\\learn-agentic-ai\\.venv\\lib\\site-packages (1.0.3)\n",
      "Collecting langchain-community\n",
      "  Downloading langchain_community-0.4.1-py3-none-any.whl.metadata (3.0 kB)\n",
      "Requirement already satisfied: python-dotenv in c:\\users\\cheahchr\\git\\learn-agentic-ai\\.venv\\lib\\site-packages (1.2.1)\n",
      "Requirement already satisfied: langchain-core<2.0.0,>=1.0.6 in c:\\users\\cheahchr\\git\\learn-agentic-ai\\.venv\\lib\\site-packages (from langchain) (1.0.7)\n",
      "Requirement already satisfied: langgraph<1.1.0,>=1.0.2 in c:\\users\\cheahchr\\git\\learn-agentic-ai\\.venv\\lib\\site-packages (from langchain) (1.0.3)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in c:\\users\\cheahchr\\git\\learn-agentic-ai\\.venv\\lib\\site-packages (from langchain) (2.12.4)\n",
      "Requirement already satisfied: jsonpatch<2.0.0,>=1.33.0 in c:\\users\\cheahchr\\git\\learn-agentic-ai\\.venv\\lib\\site-packages (from langchain-core<2.0.0,>=1.0.6->langchain) (1.33)\n",
      "Requirement already satisfied: langsmith<1.0.0,>=0.3.45 in c:\\users\\cheahchr\\git\\learn-agentic-ai\\.venv\\lib\\site-packages (from langchain-core<2.0.0,>=1.0.6->langchain) (0.4.44)\n",
      "Requirement already satisfied: packaging<26.0.0,>=23.2.0 in c:\\users\\cheahchr\\git\\learn-agentic-ai\\.venv\\lib\\site-packages (from langchain-core<2.0.0,>=1.0.6->langchain) (25.0)\n",
      "Requirement already satisfied: pyyaml<7.0.0,>=5.3.0 in c:\\users\\cheahchr\\git\\learn-agentic-ai\\.venv\\lib\\site-packages (from langchain-core<2.0.0,>=1.0.6->langchain) (6.0.3)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in c:\\users\\cheahchr\\git\\learn-agentic-ai\\.venv\\lib\\site-packages (from langchain-core<2.0.0,>=1.0.6->langchain) (9.1.2)\n",
      "Requirement already satisfied: typing-extensions<5.0.0,>=4.7.0 in c:\\users\\cheahchr\\git\\learn-agentic-ai\\.venv\\lib\\site-packages (from langchain-core<2.0.0,>=1.0.6->langchain) (4.15.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\users\\cheahchr\\git\\learn-agentic-ai\\.venv\\lib\\site-packages (from jsonpatch<2.0.0,>=1.33.0->langchain-core<2.0.0,>=1.0.6->langchain) (3.0.0)\n",
      "Requirement already satisfied: langgraph-checkpoint<4.0.0,>=2.1.0 in c:\\users\\cheahchr\\git\\learn-agentic-ai\\.venv\\lib\\site-packages (from langgraph<1.1.0,>=1.0.2->langchain) (3.0.1)\n",
      "Requirement already satisfied: langgraph-prebuilt<1.1.0,>=1.0.2 in c:\\users\\cheahchr\\git\\learn-agentic-ai\\.venv\\lib\\site-packages (from langgraph<1.1.0,>=1.0.2->langchain) (1.0.4)\n",
      "Requirement already satisfied: langgraph-sdk<0.3.0,>=0.2.2 in c:\\users\\cheahchr\\git\\learn-agentic-ai\\.venv\\lib\\site-packages (from langgraph<1.1.0,>=1.0.2->langchain) (0.2.9)\n",
      "Requirement already satisfied: xxhash>=3.5.0 in c:\\users\\cheahchr\\git\\learn-agentic-ai\\.venv\\lib\\site-packages (from langgraph<1.1.0,>=1.0.2->langchain) (3.6.0)\n",
      "Requirement already satisfied: ormsgpack>=1.12.0 in c:\\users\\cheahchr\\git\\learn-agentic-ai\\.venv\\lib\\site-packages (from langgraph-checkpoint<4.0.0,>=2.1.0->langgraph<1.1.0,>=1.0.2->langchain) (1.12.0)\n",
      "Requirement already satisfied: httpx>=0.25.2 in c:\\users\\cheahchr\\git\\learn-agentic-ai\\.venv\\lib\\site-packages (from langgraph-sdk<0.3.0,>=0.2.2->langgraph<1.1.0,>=1.0.2->langchain) (0.28.1)\n",
      "Requirement already satisfied: orjson>=3.10.1 in c:\\users\\cheahchr\\git\\learn-agentic-ai\\.venv\\lib\\site-packages (from langgraph-sdk<0.3.0,>=0.2.2->langgraph<1.1.0,>=1.0.2->langchain) (3.11.4)\n",
      "Requirement already satisfied: requests-toolbelt>=1.0.0 in c:\\users\\cheahchr\\git\\learn-agentic-ai\\.venv\\lib\\site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.0.6->langchain) (1.0.0)\n",
      "Requirement already satisfied: requests>=2.0.0 in c:\\users\\cheahchr\\git\\learn-agentic-ai\\.venv\\lib\\site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.0.6->langchain) (2.32.5)\n",
      "Requirement already satisfied: zstandard>=0.23.0 in c:\\users\\cheahchr\\git\\learn-agentic-ai\\.venv\\lib\\site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.0.6->langchain) (0.25.0)\n",
      "Requirement already satisfied: anyio in c:\\users\\cheahchr\\git\\learn-agentic-ai\\.venv\\lib\\site-packages (from httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph<1.1.0,>=1.0.2->langchain) (4.11.0)\n",
      "Requirement already satisfied: certifi in c:\\users\\cheahchr\\git\\learn-agentic-ai\\.venv\\lib\\site-packages (from httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph<1.1.0,>=1.0.2->langchain) (2025.11.12)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\cheahchr\\git\\learn-agentic-ai\\.venv\\lib\\site-packages (from httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph<1.1.0,>=1.0.2->langchain) (1.0.9)\n",
      "Requirement already satisfied: idna in c:\\users\\cheahchr\\git\\learn-agentic-ai\\.venv\\lib\\site-packages (from httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph<1.1.0,>=1.0.2->langchain) (3.11)\n",
      "Requirement already satisfied: h11>=0.16 in c:\\users\\cheahchr\\git\\learn-agentic-ai\\.venv\\lib\\site-packages (from httpcore==1.*->httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph<1.1.0,>=1.0.2->langchain) (0.16.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\cheahchr\\git\\learn-agentic-ai\\.venv\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.41.5 in c:\\users\\cheahchr\\git\\learn-agentic-ai\\.venv\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.41.5)\n",
      "Requirement already satisfied: typing-inspection>=0.4.2 in c:\\users\\cheahchr\\git\\learn-agentic-ai\\.venv\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.4.2)\n",
      "Requirement already satisfied: openai<3.0.0,>=1.109.1 in c:\\users\\cheahchr\\git\\learn-agentic-ai\\.venv\\lib\\site-packages (from langchain-openai) (2.8.1)\n",
      "Requirement already satisfied: tiktoken<1.0.0,>=0.7.0 in c:\\users\\cheahchr\\git\\learn-agentic-ai\\.venv\\lib\\site-packages (from langchain-openai) (0.12.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in c:\\users\\cheahchr\\git\\learn-agentic-ai\\.venv\\lib\\site-packages (from openai<3.0.0,>=1.109.1->langchain-openai) (1.9.0)\n",
      "Requirement already satisfied: jiter<1,>=0.10.0 in c:\\users\\cheahchr\\git\\learn-agentic-ai\\.venv\\lib\\site-packages (from openai<3.0.0,>=1.109.1->langchain-openai) (0.12.0)\n",
      "Requirement already satisfied: sniffio in c:\\users\\cheahchr\\git\\learn-agentic-ai\\.venv\\lib\\site-packages (from openai<3.0.0,>=1.109.1->langchain-openai) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in c:\\users\\cheahchr\\git\\learn-agentic-ai\\.venv\\lib\\site-packages (from openai<3.0.0,>=1.109.1->langchain-openai) (4.67.1)\n",
      "Requirement already satisfied: regex>=2022.1.18 in c:\\users\\cheahchr\\git\\learn-agentic-ai\\.venv\\lib\\site-packages (from tiktoken<1.0.0,>=0.7.0->langchain-openai) (2025.11.3)\n",
      "Collecting langchain-classic<2.0.0,>=1.0.0 (from langchain-community)\n",
      "  Downloading langchain_classic-1.0.0-py3-none-any.whl.metadata (3.9 kB)\n",
      "Collecting SQLAlchemy<3.0.0,>=1.4.0 (from langchain-community)\n",
      "  Using cached sqlalchemy-2.0.44-py3-none-any.whl.metadata (9.5 kB)\n",
      "Collecting aiohttp<4.0.0,>=3.8.3 (from langchain-community)\n",
      "  Downloading aiohttp-3.13.2-cp314-cp314-win_amd64.whl.metadata (8.4 kB)\n",
      "Collecting dataclasses-json<0.7.0,>=0.6.7 (from langchain-community)\n",
      "  Downloading dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n",
      "Collecting pydantic-settings<3.0.0,>=2.10.1 (from langchain-community)\n",
      "  Downloading pydantic_settings-2.12.0-py3-none-any.whl.metadata (3.4 kB)\n",
      "Collecting httpx-sse<1.0.0,>=0.4.0 (from langchain-community)\n",
      "  Downloading httpx_sse-0.4.3-py3-none-any.whl.metadata (9.7 kB)\n",
      "Collecting numpy>=2.1.0 (from langchain-community)\n",
      "  Downloading numpy-2.3.5-cp314-cp314-win_amd64.whl.metadata (60 kB)\n",
      "Collecting aiohappyeyeballs>=2.5.0 (from aiohttp<4.0.0,>=3.8.3->langchain-community)\n",
      "  Using cached aiohappyeyeballs-2.6.1-py3-none-any.whl.metadata (5.9 kB)\n",
      "Collecting aiosignal>=1.4.0 (from aiohttp<4.0.0,>=3.8.3->langchain-community)\n",
      "  Using cached aiosignal-1.4.0-py3-none-any.whl.metadata (3.7 kB)\n",
      "Collecting attrs>=17.3.0 (from aiohttp<4.0.0,>=3.8.3->langchain-community)\n",
      "  Using cached attrs-25.4.0-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting frozenlist>=1.1.1 (from aiohttp<4.0.0,>=3.8.3->langchain-community)\n",
      "  Using cached frozenlist-1.8.0-cp314-cp314-win_amd64.whl.metadata (21 kB)\n",
      "Collecting multidict<7.0,>=4.5 (from aiohttp<4.0.0,>=3.8.3->langchain-community)\n",
      "  Using cached multidict-6.7.0-cp314-cp314-win_amd64.whl.metadata (5.5 kB)\n",
      "Collecting propcache>=0.2.0 (from aiohttp<4.0.0,>=3.8.3->langchain-community)\n",
      "  Using cached propcache-0.4.1-cp314-cp314-win_amd64.whl.metadata (14 kB)\n",
      "Collecting yarl<2.0,>=1.17.0 (from aiohttp<4.0.0,>=3.8.3->langchain-community)\n",
      "  Using cached yarl-1.22.0-cp314-cp314-win_amd64.whl.metadata (77 kB)\n",
      "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7.0,>=0.6.7->langchain-community)\n",
      "  Downloading marshmallow-3.26.1-py3-none-any.whl.metadata (7.3 kB)\n",
      "Collecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7.0,>=0.6.7->langchain-community)\n",
      "  Downloading typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
      "Collecting langchain-text-splitters<2.0.0,>=1.0.0 (from langchain-classic<2.0.0,>=1.0.0->langchain-community)\n",
      "  Downloading langchain_text_splitters-1.0.0-py3-none-any.whl.metadata (2.6 kB)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\cheahchr\\git\\learn-agentic-ai\\.venv\\lib\\site-packages (from requests>=2.0.0->langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.0.6->langchain) (3.4.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\cheahchr\\git\\learn-agentic-ai\\.venv\\lib\\site-packages (from requests>=2.0.0->langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.0.6->langchain) (2.5.0)\n",
      "Collecting greenlet>=1 (from SQLAlchemy<3.0.0,>=1.4.0->langchain-community)\n",
      "  Using cached greenlet-3.2.4-cp314-cp314-win_amd64.whl.metadata (4.2 kB)\n",
      "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7.0,>=0.6.7->langchain-community)\n",
      "  Downloading mypy_extensions-1.1.0-py3-none-any.whl.metadata (1.1 kB)\n",
      "Requirement already satisfied: colorama in c:\\users\\cheahchr\\git\\learn-agentic-ai\\.venv\\lib\\site-packages (from tqdm>4->openai<3.0.0,>=1.109.1->langchain-openai) (0.4.6)\n",
      "Downloading langchain_community-0.4.1-py3-none-any.whl (2.5 MB)\n",
      "   ---------------------------------------- 0.0/2.5 MB ? eta -:--:--\n",
      "   -------------------- ------------------- 1.3/2.5 MB 10.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 2.5/2.5 MB 11.4 MB/s  0:00:00\n",
      "Downloading aiohttp-3.13.2-cp314-cp314-win_amd64.whl (457 kB)\n",
      "Downloading dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
      "Downloading httpx_sse-0.4.3-py3-none-any.whl (9.0 kB)\n",
      "Downloading langchain_classic-1.0.0-py3-none-any.whl (1.0 MB)\n",
      "   ---------------------------------------- 0.0/1.0 MB ? eta -:--:--\n",
      "   ---------------------------------------- 1.0/1.0 MB 13.2 MB/s  0:00:00\n",
      "Downloading langchain_text_splitters-1.0.0-py3-none-any.whl (33 kB)\n",
      "Downloading marshmallow-3.26.1-py3-none-any.whl (50 kB)\n",
      "Using cached multidict-6.7.0-cp314-cp314-win_amd64.whl (45 kB)\n",
      "Downloading pydantic_settings-2.12.0-py3-none-any.whl (51 kB)\n",
      "Using cached sqlalchemy-2.0.44-py3-none-any.whl (1.9 MB)\n",
      "Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
      "Using cached yarl-1.22.0-cp314-cp314-win_amd64.whl (88 kB)\n",
      "Using cached aiohappyeyeballs-2.6.1-py3-none-any.whl (15 kB)\n",
      "Using cached aiosignal-1.4.0-py3-none-any.whl (7.5 kB)\n",
      "Using cached attrs-25.4.0-py3-none-any.whl (67 kB)\n",
      "Using cached frozenlist-1.8.0-cp314-cp314-win_amd64.whl (44 kB)\n",
      "Using cached greenlet-3.2.4-cp314-cp314-win_amd64.whl (303 kB)\n",
      "Downloading mypy_extensions-1.1.0-py3-none-any.whl (5.0 kB)\n",
      "Downloading numpy-2.3.5-cp314-cp314-win_amd64.whl (12.9 MB)\n",
      "   ---------------------------------------- 0.0/12.9 MB ? eta -:--:--\n",
      "   -------------- ------------------------- 4.7/12.9 MB 23.5 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 11.5/12.9 MB 27.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 12.9/12.9 MB 24.3 MB/s  0:00:00\n",
      "Using cached propcache-0.4.1-cp314-cp314-win_amd64.whl (41 kB)\n",
      "Installing collected packages: propcache, numpy, mypy-extensions, multidict, marshmallow, httpx-sse, greenlet, frozenlist, attrs, aiohappyeyeballs, yarl, typing-inspect, SQLAlchemy, aiosignal, pydantic-settings, dataclasses-json, aiohttp, langchain-text-splitters, langchain-classic, langchain-community\n",
      "\n",
      "   -- -------------------------------------  1/20 [numpy]\n",
      "   -- -------------------------------------  1/20 [numpy]\n",
      "   -- -------------------------------------  1/20 [numpy]\n",
      "   -- -------------------------------------  1/20 [numpy]\n",
      "   -- -------------------------------------  1/20 [numpy]\n",
      "   -- -------------------------------------  1/20 [numpy]\n",
      "   -- -------------------------------------  1/20 [numpy]\n",
      "   -- -------------------------------------  1/20 [numpy]\n",
      "   -- -------------------------------------  1/20 [numpy]\n",
      "   -- -------------------------------------  1/20 [numpy]\n",
      "   -- -------------------------------------  1/20 [numpy]\n",
      "   -- -------------------------------------  1/20 [numpy]\n",
      "   -- -------------------------------------  1/20 [numpy]\n",
      "   -- -------------------------------------  1/20 [numpy]\n",
      "   -- -------------------------------------  1/20 [numpy]\n",
      "   -- -------------------------------------  1/20 [numpy]\n",
      "   -- -------------------------------------  1/20 [numpy]\n",
      "   -- -------------------------------------  1/20 [numpy]\n",
      "   -- -------------------------------------  1/20 [numpy]\n",
      "   -- -------------------------------------  1/20 [numpy]\n",
      "   -- -------------------------------------  1/20 [numpy]\n",
      "   -- -------------------------------------  1/20 [numpy]\n",
      "   -- -------------------------------------  1/20 [numpy]\n",
      "   -- -------------------------------------  1/20 [numpy]\n",
      "   -- -------------------------------------  1/20 [numpy]\n",
      "   -- -------------------------------------  1/20 [numpy]\n",
      "   -- -------------------------------------  1/20 [numpy]\n",
      "   -- -------------------------------------  1/20 [numpy]\n",
      "   -- -------------------------------------  1/20 [numpy]\n",
      "   -- -------------------------------------  1/20 [numpy]\n",
      "   -- -------------------------------------  1/20 [numpy]\n",
      "   ------ ---------------------------------  3/20 [multidict]\n",
      "   -------- -------------------------------  4/20 [marshmallow]\n",
      "   ---------- -----------------------------  5/20 [httpx-sse]\n",
      "   ------------ ---------------------------  6/20 [greenlet]\n",
      "   ------------ ---------------------------  6/20 [greenlet]\n",
      "   ------------ ---------------------------  6/20 [greenlet]\n",
      "   ---------------- -----------------------  8/20 [attrs]\n",
      "   ------------------ ---------------------  9/20 [aiohappyeyeballs]\n",
      "   ------------------------ --------------- 12/20 [SQLAlchemy]\n",
      "   ------------------------ --------------- 12/20 [SQLAlchemy]\n",
      "   ------------------------ --------------- 12/20 [SQLAlchemy]\n",
      "   ------------------------ --------------- 12/20 [SQLAlchemy]\n",
      "   ------------------------ --------------- 12/20 [SQLAlchemy]\n",
      "   ------------------------ --------------- 12/20 [SQLAlchemy]\n",
      "   ------------------------ --------------- 12/20 [SQLAlchemy]\n",
      "   ------------------------ --------------- 12/20 [SQLAlchemy]\n",
      "   ------------------------ --------------- 12/20 [SQLAlchemy]\n",
      "   ------------------------ --------------- 12/20 [SQLAlchemy]\n",
      "   ------------------------ --------------- 12/20 [SQLAlchemy]\n",
      "   ------------------------ --------------- 12/20 [SQLAlchemy]\n",
      "   ------------------------ --------------- 12/20 [SQLAlchemy]\n",
      "   ------------------------ --------------- 12/20 [SQLAlchemy]\n",
      "   ------------------------ --------------- 12/20 [SQLAlchemy]\n",
      "   ------------------------ --------------- 12/20 [SQLAlchemy]\n",
      "   ------------------------ --------------- 12/20 [SQLAlchemy]\n",
      "   ------------------------ --------------- 12/20 [SQLAlchemy]\n",
      "   ------------------------ --------------- 12/20 [SQLAlchemy]\n",
      "   ---------------------------- ----------- 14/20 [pydantic-settings]\n",
      "   ------------------------------ --------- 15/20 [dataclasses-json]\n",
      "   -------------------------------- ------- 16/20 [aiohttp]\n",
      "   -------------------------------- ------- 16/20 [aiohttp]\n",
      "   -------------------------------- ------- 16/20 [aiohttp]\n",
      "   ---------------------------------- ----- 17/20 [langchain-text-splitters]\n",
      "   ------------------------------------ --- 18/20 [langchain-classic]\n",
      "   ------------------------------------ --- 18/20 [langchain-classic]\n",
      "   ------------------------------------ --- 18/20 [langchain-classic]\n",
      "   ------------------------------------ --- 18/20 [langchain-classic]\n",
      "   ------------------------------------ --- 18/20 [langchain-classic]\n",
      "   ------------------------------------ --- 18/20 [langchain-classic]\n",
      "   ------------------------------------ --- 18/20 [langchain-classic]\n",
      "   ------------------------------------ --- 18/20 [langchain-classic]\n",
      "   ------------------------------------ --- 18/20 [langchain-classic]\n",
      "   ------------------------------------ --- 18/20 [langchain-classic]\n",
      "   ------------------------------------ --- 18/20 [langchain-classic]\n",
      "   ------------------------------------ --- 18/20 [langchain-classic]\n",
      "   ------------------------------------ --- 18/20 [langchain-classic]\n",
      "   ------------------------------------ --- 18/20 [langchain-classic]\n",
      "   ------------------------------------ --- 18/20 [langchain-classic]\n",
      "   ------------------------------------ --- 18/20 [langchain-classic]\n",
      "   ------------------------------------ --- 18/20 [langchain-classic]\n",
      "   ------------------------------------ --- 18/20 [langchain-classic]\n",
      "   ------------------------------------ --- 18/20 [langchain-classic]\n",
      "   ------------------------------------ --- 18/20 [langchain-classic]\n",
      "   ------------------------------------ --- 18/20 [langchain-classic]\n",
      "   ------------------------------------ --- 18/20 [langchain-classic]\n",
      "   ------------------------------------ --- 18/20 [langchain-classic]\n",
      "   ------------------------------------ --- 18/20 [langchain-classic]\n",
      "   ------------------------------------ --- 18/20 [langchain-classic]\n",
      "   ------------------------------------ --- 18/20 [langchain-classic]\n",
      "   ------------------------------------ --- 18/20 [langchain-classic]\n",
      "   ------------------------------------ --- 18/20 [langchain-classic]\n",
      "   ------------------------------------ --- 18/20 [langchain-classic]\n",
      "   ------------------------------------ --- 18/20 [langchain-classic]\n",
      "   ------------------------------------ --- 18/20 [langchain-classic]\n",
      "   ------------------------------------ --- 18/20 [langchain-classic]\n",
      "   ------------------------------------ --- 18/20 [langchain-classic]\n",
      "   ------------------------------------ --- 18/20 [langchain-classic]\n",
      "   ------------------------------------ --- 18/20 [langchain-classic]\n",
      "   ------------------------------------ --- 18/20 [langchain-classic]\n",
      "   ------------------------------------ --- 18/20 [langchain-classic]\n",
      "   ------------------------------------ --- 18/20 [langchain-classic]\n",
      "   ------------------------------------ --- 18/20 [langchain-classic]\n",
      "   ------------------------------------ --- 18/20 [langchain-classic]\n",
      "   ------------------------------------ --- 18/20 [langchain-classic]\n",
      "   ------------------------------------ --- 18/20 [langchain-classic]\n",
      "   ------------------------------------ --- 18/20 [langchain-classic]\n",
      "   ------------------------------------ --- 18/20 [langchain-classic]\n",
      "   ------------------------------------ --- 18/20 [langchain-classic]\n",
      "   ------------------------------------ --- 18/20 [langchain-classic]\n",
      "   ------------------------------------ --- 18/20 [langchain-classic]\n",
      "   -------------------------------------- - 19/20 [langchain-community]\n",
      "   -------------------------------------- - 19/20 [langchain-community]\n",
      "   -------------------------------------- - 19/20 [langchain-community]\n",
      "   -------------------------------------- - 19/20 [langchain-community]\n",
      "   -------------------------------------- - 19/20 [langchain-community]\n",
      "   -------------------------------------- - 19/20 [langchain-community]\n",
      "   -------------------------------------- - 19/20 [langchain-community]\n",
      "   -------------------------------------- - 19/20 [langchain-community]\n",
      "   -------------------------------------- - 19/20 [langchain-community]\n",
      "   -------------------------------------- - 19/20 [langchain-community]\n",
      "   -------------------------------------- - 19/20 [langchain-community]\n",
      "   -------------------------------------- - 19/20 [langchain-community]\n",
      "   -------------------------------------- - 19/20 [langchain-community]\n",
      "   -------------------------------------- - 19/20 [langchain-community]\n",
      "   -------------------------------------- - 19/20 [langchain-community]\n",
      "   -------------------------------------- - 19/20 [langchain-community]\n",
      "   -------------------------------------- - 19/20 [langchain-community]\n",
      "   -------------------------------------- - 19/20 [langchain-community]\n",
      "   -------------------------------------- - 19/20 [langchain-community]\n",
      "   -------------------------------------- - 19/20 [langchain-community]\n",
      "   -------------------------------------- - 19/20 [langchain-community]\n",
      "   -------------------------------------- - 19/20 [langchain-community]\n",
      "   -------------------------------------- - 19/20 [langchain-community]\n",
      "   -------------------------------------- - 19/20 [langchain-community]\n",
      "   -------------------------------------- - 19/20 [langchain-community]\n",
      "   -------------------------------------- - 19/20 [langchain-community]\n",
      "   -------------------------------------- - 19/20 [langchain-community]\n",
      "   -------------------------------------- - 19/20 [langchain-community]\n",
      "   -------------------------------------- - 19/20 [langchain-community]\n",
      "   -------------------------------------- - 19/20 [langchain-community]\n",
      "   -------------------------------------- - 19/20 [langchain-community]\n",
      "   -------------------------------------- - 19/20 [langchain-community]\n",
      "   -------------------------------------- - 19/20 [langchain-community]\n",
      "   -------------------------------------- - 19/20 [langchain-community]\n",
      "   -------------------------------------- - 19/20 [langchain-community]\n",
      "   -------------------------------------- - 19/20 [langchain-community]\n",
      "   -------------------------------------- - 19/20 [langchain-community]\n",
      "   -------------------------------------- - 19/20 [langchain-community]\n",
      "   -------------------------------------- - 19/20 [langchain-community]\n",
      "   -------------------------------------- - 19/20 [langchain-community]\n",
      "   -------------------------------------- - 19/20 [langchain-community]\n",
      "   -------------------------------------- - 19/20 [langchain-community]\n",
      "   -------------------------------------- - 19/20 [langchain-community]\n",
      "   -------------------------------------- - 19/20 [langchain-community]\n",
      "   -------------------------------------- - 19/20 [langchain-community]\n",
      "   -------------------------------------- - 19/20 [langchain-community]\n",
      "   -------------------------------------- - 19/20 [langchain-community]\n",
      "   -------------------------------------- - 19/20 [langchain-community]\n",
      "   -------------------------------------- - 19/20 [langchain-community]\n",
      "   -------------------------------------- - 19/20 [langchain-community]\n",
      "   -------------------------------------- - 19/20 [langchain-community]\n",
      "   -------------------------------------- - 19/20 [langchain-community]\n",
      "   -------------------------------------- - 19/20 [langchain-community]\n",
      "   -------------------------------------- - 19/20 [langchain-community]\n",
      "   -------------------------------------- - 19/20 [langchain-community]\n",
      "   -------------------------------------- - 19/20 [langchain-community]\n",
      "   -------------------------------------- - 19/20 [langchain-community]\n",
      "   -------------------------------------- - 19/20 [langchain-community]\n",
      "   -------------------------------------- - 19/20 [langchain-community]\n",
      "   -------------------------------------- - 19/20 [langchain-community]\n",
      "   -------------------------------------- - 19/20 [langchain-community]\n",
      "   -------------------------------------- - 19/20 [langchain-community]\n",
      "   -------------------------------------- - 19/20 [langchain-community]\n",
      "   -------------------------------------- - 19/20 [langchain-community]\n",
      "   -------------------------------------- - 19/20 [langchain-community]\n",
      "   -------------------------------------- - 19/20 [langchain-community]\n",
      "   -------------------------------------- - 19/20 [langchain-community]\n",
      "   -------------------------------------- - 19/20 [langchain-community]\n",
      "   -------------------------------------- - 19/20 [langchain-community]\n",
      "   -------------------------------------- - 19/20 [langchain-community]\n",
      "   -------------------------------------- - 19/20 [langchain-community]\n",
      "   -------------------------------------- - 19/20 [langchain-community]\n",
      "   -------------------------------------- - 19/20 [langchain-community]\n",
      "   -------------------------------------- - 19/20 [langchain-community]\n",
      "   -------------------------------------- - 19/20 [langchain-community]\n",
      "   -------------------------------------- - 19/20 [langchain-community]\n",
      "   -------------------------------------- - 19/20 [langchain-community]\n",
      "   -------------------------------------- - 19/20 [langchain-community]\n",
      "   -------------------------------------- - 19/20 [langchain-community]\n",
      "   ---------------------------------------- 20/20 [langchain-community]\n",
      "\n",
      "Successfully installed SQLAlchemy-2.0.44 aiohappyeyeballs-2.6.1 aiohttp-3.13.2 aiosignal-1.4.0 attrs-25.4.0 dataclasses-json-0.6.7 frozenlist-1.8.0 greenlet-3.2.4 httpx-sse-0.4.3 langchain-classic-1.0.0 langchain-community-0.4.1 langchain-text-splitters-1.0.0 marshmallow-3.26.1 multidict-6.7.0 mypy-extensions-1.1.0 numpy-2.3.5 propcache-0.4.1 pydantic-settings-2.12.0 typing-inspect-0.9.0 yarl-1.22.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install langchain langchain-openai langchain-community python-dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "79c855cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- First Interaction ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\cheahchr\\git\\learn-agentic-ai\\.venv\\Lib\\site-packages\\pydantic\\v1\\main.py:1054: UserWarning: LangSmith now uses UUID v7 for run and trace identifiers. This warning appears when passing custom IDs. Please use: from langsmith import uuid7\n",
      "            id = uuid7()\n",
      "Future versions will require UUID v7.\n",
      "  input_data = validator(cls_, input_data)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AI: Ahoy there, Alex! I see ye be wanting a weather update for Tortuga, eeh? Well, let me just check me magic weather map... Oh wait, I'm a pirate, not a meteorologist! But let's just say it'd be as unpredictable as a pirate's mood after runnin' out o' rum. Keep yer hat on, and prepare for anything from a calm sea breeze to a full-blown tropical tempest. Fair winds to ye, matey!\n",
      "\n",
      "--- Second Interaction (same session) ---\n",
      "AI: Aye, Alex, I remember yer name like the taste of a fine barrel of rum! But if I ever forget, just call for \"matey,\" and I'll be there, ready to assist on this digital voyage o' yours. Arrr!\n",
      "\n",
      "--- New Conversation (different session) ---\n",
      "AI: A black hole is a region in space where gravity is so strong that nothing, not even light, can escape from it. This happens because a large amount of mass is squeezed into a very small space. Imagine squishing the entire mass of a large star into a ball only a few kilometers wide!\n",
      "\n",
      "Black holes are often formed when massive stars reach the end of their life. After a star like this uses up all its nuclear fuel, it can no longer hold itself up against the force of gravity and collapses into a very dense object, eventually becoming a black hole.\n",
      "\n",
      "At the very center of a black hole lies a point called the \"singularity,\" where the laws of physics as we know them break down. Surrounding the singularity is the \"event horizon,\" the point of no return â€“ once something crosses this boundary, it cannot escape the black hole's pull.\n",
      "\n",
      "While black holes are invisible because light cannot escape them, we can detect their presence by observing the effects of their gravity on nearby stars and gas. Additionally, when matter falls into a black hole, it can heat up and emit X-rays, which astronomers can detect with special telescopes.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain_core.chat_history import BaseChatMessageHistory\n",
    "from langchain_community.chat_message_histories import ChatMessageHistory\n",
    "from langchain_core.runnables.history import RunnableWithMessageHistory\n",
    "\n",
    "# --- 1. Environment and API Key Setup ---\n",
    "# Load environment variables from .env file\n",
    "load_dotenv()\n",
    "\n",
    "# --- 2. Session-Based History Store ---\n",
    "# This dictionary will store chat histories for different sessions\n",
    "store = {}\n",
    "\n",
    "def get_session_history(session_id: str) -> BaseChatMessageHistory:\n",
    "    \"\"\"\n",
    "    Retrieves a chat message history for a given session ID.\n",
    "    If the session ID does not exist, a new history is created.\n",
    "    \"\"\"\n",
    "    if session_id not in store:\n",
    "        store[session_id] = ChatMessageHistory()\n",
    "    return store[session_id]\n",
    "\n",
    "# --- 3. The Main Chat Function (Corrected) ---\n",
    "\n",
    "# Initialize the Chat Model (can be done once)\n",
    "llm = ChatOpenAI(model=\"gpt-4o\")\n",
    "\n",
    "# Create the prompt template with a placeholder for the AI's role\n",
    "prompt_template = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"{ai_role}\"),\n",
    "    MessagesPlaceholder(variable_name=\"history\"),\n",
    "    (\"user\", \"{input}\"),\n",
    "])\n",
    "\n",
    "# Create the primary chain\n",
    "chain = prompt_template | llm\n",
    "\n",
    "# Create the final chain with history management\n",
    "# This is the key change: using RunnableWithMessageHistory\n",
    "chain_with_history = RunnableWithMessageHistory(\n",
    "    chain,\n",
    "    get_session_history,\n",
    "    input_messages_key=\"input\",\n",
    "    history_messages_key=\"history\",\n",
    ")\n",
    "\n",
    "def run_contextual_chat(session_id: str, user_input: str, ai_role: str):\n",
    "    \"\"\"\n",
    "    Runs a contextual chat session using the corrected chain.\n",
    "\n",
    "    Args:\n",
    "        session_id: A unique identifier for the conversation (e.g., \"intel123\").\n",
    "        user_input: The message from the user.\n",
    "        ai_role: The system role for the AI (e.g., \"You are a master programmer.\").\n",
    "    \"\"\"\n",
    "    # Define the configuration for this specific run, including the session_id\n",
    "    config = {\"configurable\": {\"session_id\": session_id}}\n",
    "\n",
    "    # Invoke the chain with the necessary inputs and configuration\n",
    "    response = chain_with_history.invoke(\n",
    "        {\"input\": user_input, \"ai_role\": ai_role},\n",
    "        config=config,\n",
    "    )\n",
    "\n",
    "    return response.content\n",
    "\n",
    "# --- 4. Example Usage (No changes needed here) ---\n",
    "\n",
    "# Define a session ID and the AI's role\n",
    "my_session_id = \"intel123\"\n",
    "my_ai_role = \"You are a sarcastic assistant who is secretly a pirate.\"\n",
    "\n",
    "# First interaction\n",
    "print(\"--- First Interaction ---\")\n",
    "response1 = run_contextual_chat(my_session_id, \"My name is Alex. What's the weather like in Tortuga?\", my_ai_role)\n",
    "print(f\"AI: {response1}\\n\")\n",
    "\n",
    "# Second interaction in the same session\n",
    "print(\"--- Second Interaction (same session) ---\")\n",
    "response2 = run_contextual_chat(my_session_id, \"Do you remember my name?\", my_ai_role)\n",
    "print(f\"AI: {response2}\\n\")\n",
    "\n",
    "# Start a new, separate conversation with a different session ID and role\n",
    "print(\"--- New Conversation (different session) ---\")\n",
    "new_session_id = \"nasa456\"\n",
    "new_ai_role = \"You are a helpful NASA scientist explaining complex topics simply.\"\n",
    "response3 = run_contextual_chat(new_session_id, \"What is a black hole?\", new_ai_role)\n",
    "print(f\"AI: {response3}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
